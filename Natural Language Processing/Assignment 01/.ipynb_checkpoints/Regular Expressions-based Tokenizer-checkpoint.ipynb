{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Name: </b> MANAY, Justin Gabrielle A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise # 01: Regular Expressions-based Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. HOW IT WORKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `re` package, which allows us to use regular expressions in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the article into a string, making sure that we exclude the byline (first 4 lines). We also make all the words in the article lowercase, as we do not want to distinguish between say \"According\" and \"according.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load article into a string.\n",
    "article_txt = open(\"S18 Text File.txt\", \"r\", encoding = \"utf8\")\n",
    "article_lines = article_txt.readlines()\n",
    "\n",
    "article = \"\"\n",
    "for i in range(len(article_lines)):\n",
    "    if(i >= 5):\n",
    "        article += article_lines[i]\n",
    "        \n",
    "# Set to lowercase.\n",
    "article = article.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the apostrophe used in the text is `’` and not `'`, so we replace it using `re.sub` for convenience. We then use a regular expression to extract all words with apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace apostrophe.\n",
    "article = re.sub(\"’\", \"'\", article)\n",
    "\n",
    "# Find all words with apostrophes.\n",
    "withApostrophe = re.findall(r\"\\b\\w+\\'\\w+\\b\", article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"it's\", \"can't\", \"gonzalez's\", \"everyone's\", \"there's\", \"isn't\", \"isn't\", \"filipino's\", \"it'll\"]\n"
     ]
    }
   ],
   "source": [
    "print(withApostrophe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these words will be contractions, and some will be possessives. We thus change the words accordingly. \n",
    "\n",
    "Since regular expression matches are non-iterable, we would have to replace the words one by one, since conditional replacements are not possible with regular expressions.\n",
    "\n",
    "Therefore, we use `string.replace` instead. Using `string.replace`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify words with apostrophes.\n",
    "for word in withApostrophe:\n",
    "    if word == \"can't\":\n",
    "        article = article.replace(\"can't\", \"can not\")\n",
    "    elif word == \"isn't\":\n",
    "        article = article.replace(\"isn't\", \"is not\")\n",
    "    elif \"'ll\" in word:\n",
    "        article = article.replace(word, word[:len(word) - 3] + \" will\")\n",
    "    elif word == \"it's\" or word == \"there's\":\n",
    "        article = article.replace(word, word[:len(word) - 2] + \" is\")\n",
    "    else:\n",
    "        article = article.replace(word, word[:len(word) - 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code, we lengthen the contractions and remove the `'s` from possessives. We base the conditions on the words in `withApostrophe` that we had extracted earlier using regular expressions.\n",
    "\n",
    "We can choose to replace the apostrophe with ` no` in the case where the word ends with `'t`, but this would turn `isn't` into `isnnot`. Since there are only two such cases ending in `'t`, we simply have cases for each one.\n",
    "\n",
    "The code works for all such words ending in `'ll`. However, for words ending in `'s`, they can be either contractions or possessives. Since we need the part of speech of the word in order to determine this, we simply create a case for the contractions that we know are in the article (`It's` and `there's`) and one for the possessives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would also like to not differentiate between certain terms like `conyo` and `conyo-tic`, or `come` and `came`.\n",
    "Thus, we simply replace all instances of the latter with the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace words\n",
    "article = re.sub(\"conyo-tic\", \"conyo\", article)\n",
    "article = re.sub(\"came\", \"come\", article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have other such cases, where words end in `-s` (plural/present tense singular), `-ing` or `-ed`. Take the word, `take` for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['takes', 'take']\n",
      "['emerged', 'emerging']\n"
     ]
    }
   ],
   "source": [
    "# Check for multiple instances of the words \"take\" and \"emerge.\"\n",
    "print(re.findall(r\"\\btak(?:es?|ing)?\\b\", article))\n",
    "print(re.findall(r\"\\bemerg(?:e[sd]?|ing)?\\b\", article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above code, we see that `take` and `takes` and `emerged` and `emerging` occur in the article, but we would like to count both variants as `take` and `emerge`, respectively. Thus, we would have to \"stem\" some of the nouns/verbs, particularly those ending in `-s`, `-ing` and `-ed`. As you'll see later on, we would have to do this manually for some nouns/verbs, so we ignore those whose plurals, present tense or past tense are irregular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all words with five letters or more ending in -s, -ing and -ed.\n",
    "toStem = re.findall(r\"\\b(\\w\\w\\w\\w+)(s|ing|ed)\\b\", article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first review the regular expression above. We use parentheses to group our output into two, the root and the suffix. We use four `\\w`'s to limit our search to words with five letters or more, to avoid words like `is`, `as` and `this`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('shoe', 's'), ('talk', 's'), ('alway', 's'), ('seem', 's'), ('associat', 'ed'), ('dres', 's'), ('sometime', 's'), ('speak', 'ing'), ('start', 'ed'), ('origin', 's'), ('student', 's'), ('idea', 's'), ('mean', 's'), ('take', 's'), ('talk', 'ing'), ('teache', 's'), ('englishe', 's'), ('linguistic', 's'), ('happen', 's'), ('research', 'ing'), ('search', 'ed'), ('mean', 'ing'), ('acros', 's'), ('refer', 's'), ('point', 'ed'), ('mean', 'ing'), ('mean', 'ing'), ('intertwin', 'ing'), ('alter', 'ing'), ('statement', 's'), ('replac', 'ing'), ('verb', 's'), ('equivalent', 's'), ('insert', 'ing'), ('result', 'ing'), ('phrase', 's'), ('fishball', 's'), ('accord', 'ing'), ('emerg', 'ed'), ('cite', 's'), ('start', 'ed'), ('teacher', 's'), ('start', 'ing'), ('teacher', 's'), ('hypothesize', 's'), ('evolv', 'ed'), ('1940', 's'), ('1950', 's'), ('origin', 's'), ('continue', 's'), ('filipino', 's'), ('know', 'ing'), ('language', 's'), ('speak', 'ing'), ('nowaday', 's'), ('seem', 's'), ('associat', 'ed'), ('student', 's'), ('seem', 'ed'), ('speak', 'ing'), ('characteristic', 's'), ('description', 's'), ('involv', 'ed'), ('belonging', 's'), ('clothe', 's'), ('consciou', 's'), ('statu', 's'), ('associat', 'ed'), ('café', 's'), ('thing', 's'), ('toward', 's'), ('clas', 's'), ('perceiv', 'ed'), ('belong', 'ing'), ('clas', 's'), ('describe', 's'), ('speak', 'ing'), ('friend', 's'), ('themselve', 's'), ('other', 's'), ('student', 's'), ('answer', 's'), ('alway', 's'), ('word', 's'), ('sociolect', 's'), ('dialect', 's'), ('language', 's'), ('proces', 's'), ('explain', 's'), ('fledg', 'ed'), ('speaker', 's'), ('dedicat', 'ed'), ('form', 'ing'), ('word', 's'), ('user', 's'), ('endles', 's'), ('filipino', 's'), ('excite', 's'), ('excit', 'ed'), ('emerg', 'ing'), ('evolv', 'ing'), ('enthuse', 's'), ('regardles', 's'), ('continue', 's'), ('filipino', 's'), ('conyo', 's')]\n"
     ]
    }
   ],
   "source": [
    "print(toStem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output from the regular expression, we note the following:\n",
    "- Some words (such as `associated`, `emerging`, etc.) have had their final `e`'s cut. Note that there is not particular rule for this case, so we would have to do this manually (or with a word database).\n",
    "- Some words ending in `-s` have been cut incorrectly.\n",
    "    - In some cases (like `class`), the word ends in two `s`'s.\n",
    "    - In others (like `conscious`), the letter before it is a letter  which English words rarely end on.\n",
    "    - In others (like `teaches`), the ending letter is one of `s`, `x`, `z` and `h`, which means that you need to add `-es` to form the plural/present tense.\n",
    "    - In others (like `linguistics`), the ending `s` need not be cut at all.\n",
    "- For the rest of the cases, the method worked perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, based on the rules above, we again use `string.replace` to stem the words in the article. We also create a list of exceptions (`exceptions`), and a list of the verbs that have had their final `e`'s cut (`cut_verbs`), based on the output of the regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_plurals = [\"s\", \"x\", \"z\", \"h\"]\n",
    "cut_verbs = [\"associated\", \"intertwining\", \"hypothesizes\", \"replacing\", \"emerged\", \"evolved\", \"involved\", \"perceived\", \"dedicated\", \"excited\", \"emerging\", \"evolving\", \"enthuses\"]\n",
    "exceptions = [\"always\", \"sometimes\", \"linguistics\", \"according\", \"nowadays\", \"belongings\", \"clothes\", \"towards\", \"themselves\", \"fledged\"]\n",
    "\n",
    "for root, suffix in stem:\n",
    "    if (root[-1] in [\"u\", \"s\"] and suffix == \"s\") or root + suffix in exceptions:\n",
    "        continue\n",
    "    elif root[len(root) - 2] in es_plurals and suffix == \"s\":\n",
    "        article = article.replace(root + suffix, root[:-1])\n",
    "    elif root + suffix in cut_verbs:\n",
    "        article = article.replace(root + suffix, root + \"e\")\n",
    "    else:\n",
    "        article = article.replace(root + suffix, root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other words in the article which can be stemmed, such as adverbs (ending in `-ly`) and negations in adjectives (`un-`, `in-`). But they do not seem to affect the word counts too much, so we ignore them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the article for any inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“it is so init here, diba?” “those shoe are so mahal talaga!” “can you make para here, boss?”\n",
      "\n",
      "do you know anyone who talk like this?\n",
      "\n",
      "de la salle university always seem to be humorously associate with the conyo subculture, so one can not help but wonder just how the typical conyo kid come into existence. the term can be used to describe a person, their language, or even the way they act or dress. as a language, some describe it as a form of taglish, taglish spoken in a “maarte” way, or sometimes just speak in filipino with a heavy foreign accent.\n",
      "\n",
      "in spite of all this, though, does anyone really know what the exact definition of conyo is, where it start, and how it come to be?\n",
      "\n",
      "to get a better look at the origin and evolution of the word, some student give their own idea on what the term conyo mean to them. the menagerie take it a step further by also talk to dr. ariane macalinga borlongan, a professor who teach world english and english linguistics in tokyo, japan, and who also happen to be research on conyo english.\n",
      "\n",
      "a brief history\n",
      "\n",
      "those who have search for the mean of the word conyo may have come across the spanish word coño, which refer to female genitalia. as point out by dr. borlongan, it can also be used as an interjection, much like the english word ‘fuck'. evidently, this original mean is very far from (and much more offensive than) the current filipino mean of the word.\n",
      "\n",
      "so, when did people start habitually intertwine filipino and english in every sentence, alter otherwise completely english statement by replace verb with their filipino equivalent and insert noh, diba, and eh, result in phras like “making tusok-tusok the fishball”?\n",
      "\n",
      "according to dr. borlongan, it is unclear when exactly conyo english emerge, though he cite br. andrew gonzalez idea that philippine english start sometime during the american occupation, when filipino teacher were start to take the place of american teacher. from this, he hypothesiz that conyo english could have evolve from philippine english sometime during the 1940 to 1950 when english had become everyone second language.\n",
      "\n",
      "despite having unclear origin at no specific point in history, the term conyo has since set its foundation in contemporary filipino language, and it continue to be used by the youth of today. but there is more to it than just being the result of filipino know two language well. today, being conyo is not just about speak in a certain, peculiar way. nowadays, there seem to be an image of a specific type of person that is associate with the word.\n",
      "\n",
      "conyo characterization\n",
      "\n",
      "when student were asked about how they would define conyo, many of them seem to have a common idea that it is not just a manner of speak, but also a particular set of characteristic. frequently given description of a conyo person involve having expensive belongs like designer clothes, being conscious about their social status, being born into a rich family, and, most of all, being more fluent in english than the average filipino.\n",
      "the conyo culture is heavily associate with café, among other thing.\n",
      "\n",
      "basically, the term is aimed towards the youth of the upper class, or, at least, those who want to be perceive as belong to this social class. because of this, dr. borlongan describe conyo english as a sociolect, a specific language used by a social group.\n",
      "\n",
      "speak conyo may have little to do with how well a person can speak english or filipino. it could simply be a language used by someone because they are among their friend of the same culture. it may not necessarily be because they are trying to put themselves above other, or because they lack the capability to speak filipino, unlike what some student' answer imply.\n",
      "\n",
      "a conyo future\n",
      "\n",
      "just like any other kind of language, dialect, or sociolect, the filipino conyo english may still continue to evolve through time. “it is always possible to develop new word, new sociolect, new dialect, new language — that is a normal process in language evolution”, dr. borlongan explain.  therefore, it is quite possible that the conyo english we know today may just be the initial foundation of what is to become a full-fledged language in the future. it is possible that we may be able to find a dictionary specifically-made for conyo english speaker or a council dedicate to form new word for conyo english user. its potential is as endless as the future.\n",
      "\n",
      "though some filipino may not necessarily favor the emergence of conyo english, dr. borlongan says this aspect of language evolution is what actually excite him as a linguist. “i am excite at how conyo english is emerge, evolve; hence, my research is on conyo english,” he enthus.\n",
      "\n",
      "regardless of what the filipino population says about it, conyo english is here to stay. it will continue to grow as society continue to develop, so watch out filipino, because conyo may gradually invade the country as we know it.\n"
     ]
    }
   ],
   "source": [
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now process the entire article and create a frequency list (or a frequency dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidently : 1 \n",
      "\n",
      "result : 2 \n",
      "\n",
      "put : 1 \n",
      "\n",
      "imply : 1 \n",
      "\n",
      "had : 1 \n",
      "\n",
      "completely : 1 \n",
      "\n",
      "it : 18 \n",
      "\n",
      "unlike : 1 \n",
      "\n",
      "during : 2 \n",
      "\n",
      "would : 1 \n",
      "\n",
      "many : 1 \n",
      "\n",
      "simply : 1 \n",
      "\n",
      "init : 1 \n",
      "\n",
      "average : 1 \n",
      "\n",
      "through : 1 \n",
      "\n",
      "able : 1 \n",
      "\n",
      "give : 1 \n",
      "\n",
      "normal : 1 \n",
      "\n",
      "quite : 1 \n",
      "\n",
      "belong : 1 \n",
      "\n",
      "has : 1 \n",
      "\n",
      "endless : 1 \n",
      "\n",
      "define : 1 \n",
      "\n",
      "designer : 1 \n",
      "\n",
      "step : 1 \n",
      "\n",
      "fuck : 1 \n",
      "\n",
      "time : 1 \n",
      "\n",
      "act : 1 \n",
      "\n",
      "help : 1 \n",
      "\n",
      "form : 2 \n",
      "\n",
      "did : 1 \n",
      "\n",
      "foundation : 2 \n",
      "\n",
      "seem : 3 \n",
      "\n",
      "insert : 1 \n",
      "\n",
      "tusok-tusok : 1 \n",
      "\n",
      "humorously : 1 \n",
      "\n",
      "status : 1 \n",
      "\n",
      "they : 5 \n",
      "\n",
      "potential : 1 \n",
      "\n",
      "linguistics : 1 \n",
      "\n",
      "despite : 1 \n",
      "\n",
      "because : 5 \n",
      "\n",
      "user : 1 \n",
      "\n",
      "talaga : 1 \n",
      "\n",
      "dictionary : 1 \n",
      "\n",
      "search : 1 \n",
      "\n",
      "intertwine : 1 \n",
      "\n",
      "group : 1 \n",
      "\n",
      "exactly : 1 \n",
      "\n",
      "that : 7 \n",
      "\n",
      "answer : 1 \n",
      "\n",
      "not : 5 \n",
      "\n",
      "people : 1 \n",
      "\n",
      "with : 6 \n",
      "\n",
      "start : 4 \n",
      "\n",
      "well : 2 \n",
      "\n",
      "being : 5 \n",
      "\n",
      "menagerie : 1 \n",
      "\n",
      "equivalent : 1 \n",
      "\n",
      "basically : 1 \n",
      "\n",
      "themselves : 1 \n",
      "\n",
      "lack : 1 \n",
      "\n",
      "there : 2 \n",
      "\n",
      "typical : 1 \n",
      "\n",
      "take : 2 \n",
      "\n",
      "existence : 1 \n",
      "\n",
      "english : 22 \n",
      "\n",
      "happen : 1 \n",
      "\n",
      "among : 2 \n",
      "\n",
      "spanish : 1 \n",
      "\n",
      "american : 2 \n",
      "\n",
      "always : 2 \n",
      "\n",
      "borlongan : 6 \n",
      "\n",
      "come : 3 \n",
      "\n",
      "but : 3 \n",
      "\n",
      "macalinga : 1 \n",
      "\n",
      "may : 8 \n",
      "\n",
      "la : 1 \n",
      "\n",
      "much : 2 \n",
      "\n",
      "exact : 1 \n",
      "\n",
      "no : 1 \n",
      "\n",
      "of : 24 \n",
      "\n",
      "heavy : 1 \n",
      "\n",
      "ariane : 1 \n",
      "\n",
      "excite : 2 \n",
      "\n",
      "him : 1 \n",
      "\n",
      "am : 1 \n",
      "\n",
      "least : 1 \n",
      "\n",
      "about : 4 \n",
      "\n",
      "therefore : 1 \n",
      "\n",
      "invade : 1 \n",
      "\n",
      "verb : 1 \n",
      "\n",
      "salle : 1 \n",
      "\n",
      "accent : 1 \n",
      "\n",
      "definition : 1 \n",
      "\n",
      "place : 1 \n",
      "\n",
      "possible : 3 \n",
      "\n",
      "coño : 1 \n",
      "\n",
      "we : 3 \n",
      "\n",
      "were : 2 \n",
      "\n",
      "for : 3 \n",
      "\n",
      "university : 1 \n",
      "\n",
      "two : 1 \n",
      "\n",
      "continue : 4 \n",
      "\n",
      "de : 1 \n",
      "\n",
      "as : 11 \n",
      "\n",
      "could : 2 \n",
      "\n",
      "really : 1 \n",
      "\n",
      "clothes : 1 \n",
      "\n",
      "sociolect : 3 \n",
      "\n",
      "will : 1 \n",
      "\n",
      "little : 1 \n",
      "\n",
      "given : 1 \n",
      "\n",
      "most : 1 \n",
      "\n",
      "certain : 1 \n",
      "\n",
      "full-fledged : 1 \n",
      "\n",
      "out : 2 \n",
      "\n",
      "regardless : 1 \n",
      "\n",
      "spite : 1 \n",
      "\n",
      "characterization : 1 \n",
      "\n",
      "br : 1 \n",
      "\n",
      "council : 1 \n",
      "\n",
      "conscious : 1 \n",
      "\n",
      "taglish : 2 \n",
      "\n",
      "habitually : 1 \n",
      "\n",
      "interjection : 1 \n",
      "\n",
      "aimed : 1 \n",
      "\n",
      "grow : 1 \n",
      "\n",
      "upper : 1 \n",
      "\n",
      "who : 5 \n",
      "\n",
      "get : 1 \n",
      "\n",
      "family : 1 \n",
      "\n",
      "cite : 1 \n",
      "\n",
      "conyo : 26 \n",
      "\n",
      "replace : 1 \n",
      "\n",
      "para : 1 \n",
      "\n",
      "here : 3 \n",
      "\n",
      "teacher : 2 \n",
      "\n",
      "other : 3 \n",
      "\n",
      "friend : 1 \n",
      "\n",
      "all : 2 \n",
      "\n",
      "favor : 1 \n",
      "\n",
      "every : 1 \n",
      "\n",
      "frequently : 1 \n",
      "\n",
      "perceive : 1 \n",
      "\n",
      "my : 1 \n",
      "\n",
      "filipino : 14 \n",
      "\n",
      "than : 3 \n",
      "\n",
      "wonder : 1 \n",
      "\n",
      "common : 1 \n",
      "\n",
      "future : 3 \n",
      "\n",
      "having : 2 \n",
      "\n",
      "someone : 1 \n",
      "\n",
      "those : 3 \n",
      "\n",
      "one : 1 \n",
      "\n",
      "sometimes : 1 \n",
      "\n",
      "a : 27 \n",
      "\n",
      "across : 1 \n",
      "\n",
      "own : 1 \n",
      "\n",
      "expensive : 1 \n",
      "\n",
      "enthus : 1 \n",
      "\n",
      "way : 3 \n",
      "\n",
      "alter : 1 \n",
      "\n",
      "country : 1 \n",
      "\n",
      "tokyo : 1 \n",
      "\n",
      "point : 2 \n",
      "\n",
      "far : 1 \n",
      "\n",
      "emergence : 1 \n",
      "\n",
      "manner : 1 \n",
      "\n",
      "more : 3 \n",
      "\n",
      "evolution : 3 \n",
      "\n",
      "philippine : 2 \n",
      "\n",
      "new : 5 \n",
      "\n",
      "gradually : 1 \n",
      "\n",
      "into : 2 \n",
      "\n",
      "peculiar : 1 \n",
      "\n",
      "brief : 1 \n",
      "\n",
      "look : 1 \n",
      "\n",
      "aspect : 1 \n",
      "\n",
      "specifically-made : 1 \n",
      "\n",
      "andrew : 1 \n",
      "\n",
      "dr : 6 \n",
      "\n",
      "shoe : 1 \n",
      "\n",
      "emerge : 2 \n",
      "\n",
      "towards : 1 \n",
      "\n",
      "when : 5 \n",
      "\n",
      "1950 : 1 \n",
      "\n",
      "you : 2 \n",
      "\n",
      "necessarily : 2 \n",
      "\n",
      "involve : 1 \n",
      "\n",
      "develop : 2 \n",
      "\n",
      "word : 8 \n",
      "\n",
      "anyone : 2 \n",
      "\n",
      "phras : 1 \n",
      "\n",
      "student : 3 \n",
      "\n",
      "by : 6 \n",
      "\n",
      "do : 2 \n",
      "\n",
      "fishball : 1 \n",
      "\n",
      "have : 5 \n",
      "\n",
      "evolve : 3 \n",
      "\n",
      "become : 2 \n",
      "\n",
      "rich : 1 \n",
      "\n",
      "kid : 1 \n",
      "\n",
      "culture : 2 \n",
      "\n",
      "or : 8 \n",
      "\n",
      "belongs : 1 \n",
      "\n",
      "statement : 1 \n",
      "\n",
      "above : 1 \n",
      "\n",
      "he : 3 \n",
      "\n",
      "characteristic : 1 \n",
      "\n",
      "specific : 3 \n",
      "\n",
      "genitalia : 1 \n",
      "\n",
      "thing : 1 \n",
      "\n",
      "process : 1 \n",
      "\n",
      "initial : 1 \n",
      "\n",
      "image : 1 \n",
      "\n",
      "type : 1 \n",
      "\n",
      "on : 3 \n",
      "\n",
      "professor : 1 \n",
      "\n",
      "since : 1 \n",
      "\n",
      "today : 3 \n",
      "\n",
      "particular : 1 \n",
      "\n",
      "current : 1 \n",
      "\n",
      "research : 2 \n",
      "\n",
      "know : 5 \n",
      "\n",
      "watch : 1 \n",
      "\n",
      "find : 1 \n",
      "\n",
      "according : 1 \n",
      "\n",
      "so : 5 \n",
      "\n",
      "this : 7 \n",
      "\n",
      "speaker : 1 \n",
      "\n",
      "still : 1 \n",
      "\n",
      "description : 1 \n",
      "\n",
      "i : 1 \n",
      "\n",
      "associate : 3 \n",
      "\n",
      "describe : 3 \n",
      "\n",
      "unclear : 2 \n",
      "\n",
      "set : 2 \n",
      "\n",
      "asked : 1 \n",
      "\n",
      "teach : 1 \n",
      "\n",
      "at : 4 \n",
      "\n",
      "mean : 4 \n",
      "\n",
      "an : 2 \n",
      "\n",
      "fluent : 1 \n",
      "\n",
      "original : 1 \n",
      "\n",
      "person : 4 \n",
      "\n",
      "contemporary : 1 \n",
      "\n",
      "class : 2 \n",
      "\n",
      "linguist : 1 \n",
      "\n",
      "boss : 1 \n",
      "\n",
      "them : 2 \n",
      "\n",
      "their : 5 \n",
      "\n",
      "also : 4 \n",
      "\n",
      "does : 1 \n",
      "\n",
      "offensive : 1 \n",
      "\n",
      "youth : 2 \n",
      "\n",
      "used : 5 \n",
      "\n",
      "talk : 2 \n",
      "\n",
      "foreign : 1 \n",
      "\n",
      "social : 3 \n",
      "\n",
      "hypothesiz : 1 \n",
      "\n",
      "can : 5 \n",
      "\n",
      "term : 4 \n",
      "\n",
      "better : 1 \n",
      "\n",
      "to : 28 \n",
      "\n",
      "speak : 6 \n",
      "\n",
      "and : 10 \n",
      "\n",
      "capability : 1 \n",
      "\n",
      "make : 1 \n",
      "\n",
      "occupation : 1 \n",
      "\n",
      "1940 : 1 \n",
      "\n",
      "sentence : 1 \n",
      "\n",
      "making : 1 \n",
      "\n",
      "further : 1 \n",
      "\n",
      "everyone : 1 \n",
      "\n",
      "from : 3 \n",
      "\n",
      "born : 1 \n",
      "\n",
      "second : 1 \n",
      "\n",
      "origin : 2 \n",
      "\n",
      "even : 1 \n",
      "\n",
      "dialect : 2 \n",
      "\n",
      "hence : 1 \n",
      "\n",
      "nowadays : 1 \n",
      "\n",
      "history : 2 \n",
      "\n",
      "trying : 1 \n",
      "\n",
      "japan : 1 \n",
      "\n",
      "idea : 3 \n",
      "\n",
      "just : 7 \n",
      "\n",
      "the : 38 \n",
      "\n",
      "world : 1 \n",
      "\n",
      "says : 2 \n",
      "\n",
      "dress : 1 \n",
      "\n",
      "population : 1 \n",
      "\n",
      "some : 4 \n",
      "\n",
      "be : 12 \n",
      "\n",
      "which : 1 \n",
      "\n",
      "café : 1 \n",
      "\n",
      "maarte : 1 \n",
      "\n",
      "refer : 1 \n",
      "\n",
      "diba : 2 \n",
      "\n",
      "what : 6 \n",
      "\n",
      "its : 2 \n",
      "\n",
      "want : 1 \n",
      "\n",
      "same : 1 \n",
      "\n",
      "mahal : 1 \n",
      "\n",
      "very : 1 \n",
      "\n",
      "where : 1 \n",
      "\n",
      "dedicate : 1 \n",
      "\n",
      "gonzalez : 1 \n",
      "\n",
      "noh : 1 \n",
      "\n",
      "actually : 1 \n",
      "\n",
      "society : 1 \n",
      "\n",
      "how : 5 \n",
      "\n",
      "female : 1 \n",
      "\n",
      "though : 3 \n",
      "\n",
      "otherwise : 1 \n",
      "\n",
      "any : 1 \n",
      "\n",
      "kind : 1 \n",
      "\n",
      "stay : 1 \n",
      "\n",
      "heavily : 1 \n",
      "\n",
      "spoken : 1 \n",
      "\n",
      "eh : 1 \n",
      "\n",
      "like : 5 \n",
      "\n",
      "in : 12 \n",
      "\n",
      "is : 20 \n",
      "\n",
      "explain : 1 \n",
      "\n",
      "language : 12 \n",
      "\n",
      "are : 3 \n",
      "\n",
      "sometime : 2 \n",
      "\n",
      "subculture : 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding all words...\n",
    "wordList = re.findall(r\"\\b(\\w+\\-\\w+|\\w+)\\b\", article)\n",
    "\n",
    "# Create frequency \"list\"\n",
    "freqDict = dict((word, 0) for word in set(wordList))\n",
    "for word in wordList:\n",
    "    freqDict[word] += 1\n",
    "for key in freqDict.keys():\n",
    "    print(key, \":\", freqDict[key], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. ASSESSMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the tokenizer, we make a list of its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STRENGTHS:\n",
    "- The tokenizer stems nouns and verbs, so multiple instances of some words (e.g., `emerge`, `emerges`, `emerging`, `emerged`) are counted similarly.\n",
    "- The tokenizer is case-insenstive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WEAKNESSES:\n",
    "- The tokenizer works for this particular article, so we would have to change it somewhat to fit other articles.\n",
    "- The tokenizer does not stem adjectives and adverbs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
